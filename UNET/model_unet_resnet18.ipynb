{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-25T19:55:49.796504100Z",
     "start_time": "2023-08-25T19:55:49.790550700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "from model import DoubleConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "encoder.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62cc590286536a92"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "encoder_layers = list(encoder.children())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:26:44.082680800Z",
     "start_time": "2023-08-23T09:26:44.077110800Z"
    }
   },
   "id": "898c07d6443773ec"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): BasicBlock(\n    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (downsample): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (1): BasicBlock(\n    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layers[5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T09:15:02.429986700Z",
     "start_time": "2023-08-25T09:15:02.428477500Z"
    }
   },
   "id": "6c8cb5b0b2a681c9"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels=in_channels, out_channels=feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(in_channels=feature*2, out_channels=feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        # the bottom part of the UNET\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels=out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        print(f'Initial shape: {x.shape}')\n",
    "        for idx, down in enumerate(self.downs):\n",
    "            x = down(x)\n",
    "            print(f'Down no {idx}: {x.shape}')\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        print(f'Bottleneck: {x.shape}')\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # There must be a better way to do this with zip\n",
    "        # for skip_connection, up in zip(skip_connections, self.ups):\n",
    "        #     x = up(x)\n",
    "        #     concat_skip = torch.cat((skip_connection, x), 1)\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            print(f'Up no {idx}: {x.shape}')\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), 1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "            print(f'Up no {idx + 1}: {x.shape}')\n",
    "\n",
    "        return self.final_conv(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T14:16:22.315198200Z",
     "start_time": "2023-08-25T14:16:22.309242300Z"
    }
   },
   "id": "1169918b4020268c"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "class ResUNET(nn.Module):\n",
    "    def __init__(self, encoder, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(ResUNET, self).__init__()\n",
    "        # self.encoder = models.resnet18(pretrained=True)\n",
    "        self.encoder_layers = list(encoder.children())\n",
    "        self.downs = nn.ModuleList()\n",
    "        \n",
    "        # The bottom part of the network\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        \n",
    "        self.ups = nn.ModuleList()\n",
    "        \n",
    "        # Down part of the network\n",
    "        self.first_block = nn.Sequential(*self.encoder_layers[:3]) \n",
    "        self.downs.append(nn.Sequential(*self.encoder_layers[3:5]))\n",
    "        self.downs.append(self.encoder_layers[5])\n",
    "        self.downs.append(self.encoder_layers[6])\n",
    "        self.downs.append(self.encoder_layers[7])\n",
    "        \n",
    "        # Up part of the network\n",
    "        for idx, feature in enumerate(reversed(features)):\n",
    "            if idx == 0:\n",
    "                self.ups.append(nn.ConvTranspose2d(in_channels=feature*2,out_channels=feature, kernel_size=2, stride=2))\n",
    "            else:\n",
    "                self.ups.append(nn.ConvTranspose2d(in_channels=feature*2,out_channels=feature, kernel_size=2, stride=2, output_padding=1))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "            \n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels=out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections  = []\n",
    "        print(f'Initial shape: {x.shape}')\n",
    "        x = self.first_block(x)\n",
    "        print(f'First Block: {x.shape}')\n",
    "        for idx, down in enumerate(self.downs):\n",
    "            x = down(x)\n",
    "            print(f'Down no {idx}: {x.shape}')\n",
    "            skip_connections.append(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        print(f'Bottleneck: {x.shape}')\n",
    "        \n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            print(f'Up no {idx}: {x.shape}')\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            # match the shape of the skip connection and the x\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "                \n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "            print(f'Up no {idx+1}: {x.shape}')\n",
    "        \n",
    "        return self.final_conv(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T13:57:45.425598600Z",
     "start_time": "2023-08-25T13:57:45.422598600Z"
    }
   },
   "id": "a7b6b2f7f3aa9989"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mConvReLu\u001B[39;00m(nn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_channels, out_channels, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;28msuper\u001B[39m(ConvReLu, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class ConvReLu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvReLu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "class ResUNET2(nn.Module):\n",
    "    def __init__(self, encoder, out_channels=1, freeze_encoder=True):\n",
    "        super(ResUNET2, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = not freeze_encoder\n",
    "        \n",
    "        # assuming that the encoder is a resnet18\n",
    "        self.encoder_layers = list(self.encoder.children())\n",
    "        self.layer_0 = nn.Sequential(*self.encoder_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer_0_1x1 = ConvReLu(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.layer_1 = nn.Sequential(*self.encoder_layers[3:5])  # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.layer_1_1x1 = ConvReLu(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.layer_2 = self.encoder_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "        self.layer_2_1x1 = ConvReLu(128, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.layer_3 = self.encoder_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "        self.layer_3_1x1 = ConvReLu(256, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.layer_4 = self.encoder_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer_4_1x1 = ConvReLu(512, 512, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = ConvReLu(256 + 512, 512, kernel_size=3, padding=1)\n",
    "        self.conv_up2 = ConvReLu(128 + 512, 256, kernel_size=3, padding=1)\n",
    "        self.conv_up1 = ConvReLu(64 + 256, 256, kernel_size=3, padding=1)\n",
    "        self.conv_up0 = ConvReLu(64 + 256, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv_original_size0 = ConvReLu(3, 64, kernel_size=3, padding=1)    \n",
    "        self.conv_original_size1 = ConvReLu(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv_original_size2 = ConvReLu(64 + 128, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, out_channels, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_original = self.conv_original_size0(x)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer_0(x)\n",
    "        layer1 = self.layer_1(layer0)\n",
    "        layer2 = self.layer_2(layer1)\n",
    "        layer3 = self.layer_3(layer2)\n",
    "        layer4 = self.layer_4(layer3)\n",
    "        \n",
    "        layer4 = self.layer_4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer_3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer_2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "    \n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer_1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "    \n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer_0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "    \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)\n",
    "    \n",
    "        out = self.conv_last(x)\n",
    "    \n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T11:36:51.025813600Z",
     "start_time": "2023-08-28T11:36:50.758121900Z"
    }
   },
   "id": "40fa0ac89f7a34f3"
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 12 but got size 11 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[217], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# summary(model, input_size=(3, 224, 224))\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m preds \u001B[38;5;241m=\u001B[39m model(x)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutput shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpreds\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[212], line 57\u001B[0m, in \u001B[0;36mResUNET2.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     55\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupsample(layer4)\n\u001B[0;32m     56\u001B[0m layer3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_3_1x1(layer3)\n\u001B[1;32m---> 57\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([x, layer3], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     58\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_up3(x)\n\u001B[0;32m     60\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupsample(x)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 12 but got size 11 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3, 160, 160)\n",
    "x = x.to('cuda')\n",
    "model = ResUNET2(encoder=encoder, out_channels=3)\n",
    "model = model.to('cuda')\n",
    "# summary(model, input_size=(3, 224, 224))\n",
    "preds = model(x)\n",
    "print(f'Input shape: {x.shape}')\n",
    "print(f'Output shape: {preds.shape}')\n",
    "assert preds.shape == x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T08:23:05.273760500Z",
     "start_time": "2023-08-28T08:23:05.201651Z"
    }
   },
   "id": "85e09cdc5ea1da81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 128, 128))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8811ff2a77c3bac1"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: torch.Size([3, 3, 32, 32])\n",
      "First Block: torch.Size([3, 64, 16, 16])\n",
      "Down no 0: torch.Size([3, 64, 8, 8])\n",
      "Down no 1: torch.Size([3, 128, 4, 4])\n",
      "Down no 2: torch.Size([3, 256, 2, 2])\n",
      "Down no 3: torch.Size([3, 512, 1, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[187], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m ResUNET(encoder\u001B[38;5;241m=\u001B[39mencoder, out_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# print(f'Input shape: {x.shape}')\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m preds \u001B[38;5;241m=\u001B[39m model(x)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutput shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpreds\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m preds\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[124], line 40\u001B[0m, in \u001B[0;36mResUNET.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDown no \u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     38\u001B[0m     skip_connections\u001B[38;5;241m.\u001B[39mappend(x)\n\u001B[1;32m---> 40\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbottleneck(x)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBottleneck: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     43\u001B[0m skip_connections \u001B[38;5;241m=\u001B[39m skip_connections[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\PycharmProjects\\contour-proposal-network\\UNET\\model.py:20\u001B[0m, in \u001B[0;36mDoubleConv.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(x)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    460\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3, 32, 32)\n",
    "model = ResUNET(encoder=encoder, out_channels=2)\n",
    "# print(f'Input shape: {x.shape}')\n",
    "preds = model(x).to('cuda')\n",
    "print(f'Output shape: {preds.shape}')\n",
    "assert preds.shape == x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T06:06:37.205803600Z",
     "start_time": "2023-08-28T06:06:37.056144100Z"
    }
   },
   "id": "e4ca23ba4b486d2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.randn(3, 3, 100, 100)\n",
    "model = UNET(in_channels=3, out_channels=3)\n",
    "\n",
    "preds = model(x)\n",
    "print(f'Output shape: {preds.shape}')\n",
    "assert preds.shape == x.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2123c52560132317"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "87e6445e64f3f615"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
